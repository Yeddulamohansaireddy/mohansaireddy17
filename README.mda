THE DATASET IS EXTRACTED FROM KAGGLE WHICH IS https://www.kaggle.com/datasets/arjuntejaswi/plant-village 


PROBLEM STATEMENT OVERVIEW
The agriculture industry faces significant challenges in detecting and managing plant diseases, which can lead to substantial yield losses if not identified and treated promptly. The rapid advancement of machine learning and computer vision technologies has significantly improved the ability to detect and classify plant diseases. Early detection of plant diseases is crucial for preventing crop loss and ensuring food security. Traditional methods of plant disease detection are often labour-intensive and reliant on expert knowledge, which can be inconsistent and limited by human error. In contrast, modern automated systems have the potential to revolutionize this process by providing quick, accurate, and scalable solutions. Machine learning, particularly Convolutional Neural Networks (CNNs), has shown promising results in automating plant disease diagnosis by analysing images of plant leaves. CNNs are capable of detecting intricate patterns and subtle visual differences that may be overlooked by human experts. Despite the successes of CNNs in plant disease detection, challenges still exist in achieving high accuracy under varying environmental conditions. Factors such as lighting variations, background noise, and leaf orientations can drastically affect the performance of deep learning models. Moreover, access to large, high-quality datasets is often limited, particularly for lesser-known plant diseases. This restricts the ability of CNN-based models to generalize effectively across different crop types and disease conditions. While deep learning models have high potential, also come with increased computational costs and require significant resources, making them less accessible in resource-constrained environments.

TEAM MEMBERS:
1) YEDDULA MOHAN SAI REDDY.
2)GANGISETTY VENKATA HEMANTH.
3)YANNA RATHAN KUMAR REDDY.
4)YANAMALA SMAPATH KUMAR REDDY.

SOLUTION OVERVIEW:

It follows a modular approach, where each module is responsible for a specific task, making the system both scalable and maintainable. At the user interface layer, Tkinter - based GUI that allows users to interact with the system. The interface accepts user inputs (such as leaf images), displays predictions, and provides helpful information regarding the plant diseases. The backend layer consists of the machine learning model, SVM, which handles the image processing and classification. The system uses image preprocessing techniques to prepare the images, followed by feature extraction, before feeding them into the SVM model for classification. For data storage, a MySQL database is used to store images, classification results, and historical data. This ensures that the system can handle large amounts of data and provide historical insights.
The Graphical User Interface (GUI) plays a pivotal role in making the LEAF GUARD system user-friendly and easily accessible. Using Tkinter, a Python library for building desktop applications, the interface is designed with simplicity in mind, ensuring that it can be used by individuals with no technical background. The interface allows users to easily interact with the system, upload plant leaf images, and receive predictions about plant diseases. Once the application starts, users are prompted to log in to the system. After successful authentication,  can proceed to the main interface, where they can upload an image of a plant leaf. The image is then processed for disease detection. The system quickly analyses the uploaded image and presents the user with a diagnosis, detailing the specific disease or confirming that the plant is healthy. Along with the diagnosis, the system also provides helpful information about the disease, such as symptoms and treatment options, empowering users to take informed actions. The simplicity of the design ensures that even farmers who are not tech-savvy can make use of the tool with ease. The GUI can be further enhanced by incorporating features such as real-time updates, user accounts to track history, and even a notification system to alert users about new potential threats to their crops.
The image preprocessing and feature extraction steps are fundamental in preparing the images for disease detection. Raw images often contain unnecessary information, such as noise or irrelevant details, which may hinder the model’s ability to make accurate predictions. Therefore, preprocessing techniques are applied to clean and enhance the image, ensuring that only the relevant features are retained. First, the uploaded image is converted into grayscale to simplify the analysis. Colour information is not always necessary for disease detection, and grayscale images help reduce the computational complexity. The next step involves using edge detection algorithms, such as the Canny Edge Detector, to highlight the boundaries within the image. This helps in emphasizing the shapes and patterns, such as lesions or abnormal markings, that could indicate a disease. Additionally, Gaussian blur is applied to smooth the image, reducing the effect of noise and sharp edges that might interfere with the classification process. Once the image is cleaned and enhanced, feature extraction takes place. Colour histograms and texture patterns are extracted from the image, providing a representation of the leaf’s visual characteristics. These features are crucial for distinguishing between healthy and diseased leaves, as different diseases often present with unique color and texture variations.
The heart of the LEAF GUARD system is its Support Vector Machine (SVM) model, which is responsible for classifying leaf images based on the extracted features. SVM is a supervised learning model that works by finding an optimal hyperplane that best separates data points belonging to different categories. This makes it particularly well-suited for classification tasks involving complex image data, where the goal is to distinguish between various plant diseases. To train the SVM model, a dataset of labelled plant images is used. These images contain examples of healthy and diseased leaves, each labelled with the corresponding disease type. The SVM algorithm learns from these examples by analysing the relationships between the extracted features and the disease labels. The model is trained to recognize patterns within the feature space that correspond to each specific disease. Once trained, the SVM model is ready to classify new images. When a user uploads a leaf image, the system extracts the features from the image, inputs them into the trained model, and predicts the disease type. The SVM’s decision-making process is based on the learned patterns from the training data, allowing it to accurately identify plant diseases.
The prediction process begins after a leaf image is uploaded. The system uses its pre-trained machine learning model to classify the image by analysing the features and comparing them to patterns learned during training. Once the prediction is made, the results are displayed in an easily understandable format on the GUI. The user is presented with the disease classification result, which includes the name of the disease (if any) and additional information such as common symptoms and suggested treatment options. For instance, if the disease is identified as Powdery Mildew, the system will provide details about the disease’s symptoms, its impact on the plant, and the best course of action for treatment. If no disease is detected, the system will confirm that the plant appears healthy. The results are presented alongside the processed image, which highlights the areas of the leaf that led to the classification. This not only makes the prediction more transparent but also educates users about how the system arrived at its conclusion. With this feedback, farmers can make decisions based on accurate data, helping them protect their crops in a timely manner.
Efficient management of data is crucial in ensuring the smooth operation of the LEAF GUARD system. The system stores all relevant data, including images, disease classifications, and historical results, in a structured MySQL database. This database allows easy storage and retrieval of information, enabling the system to quickly access previous images and their corresponding predictions. The use of a database also ensures that the system can scale, accommodating a growing number of plant images and disease records. This feature is especially useful for farmers and researchers who may want to track the history of disease occurrences and treatment outcomes over time. By storing and organizing the data, the system can also provide insights into trends, such as recurring diseases in certain regions, allowing farmers to take proactive measures. Furthermore, the database ensures that the information displayed to the user is always up-to-date. The backend can query the database to retrieve the necessary details, such as the latest treatments or disease management techniques, ensuring that farmers have access to the most relevant and accurate information.
Image segmentation is an essential step that isolates regions of interest in the leaf images. By focusing on areas that show signs of disease, the system can improve its accuracy in detecting and classifying the disease. For example, thresholding techniques can be used to separate the infected parts of the leaf from healthy areas, helping the system focus its analysis on the relevant features. Once the image is segmented, the system visualizes the segmented areas to help the user understand which parts of the leaf contributed to the disease detection. This visualization is helpful in demonstrating the areas of the leaf that are affected by the disease, making it easier for farmers to take targeted action. Whether it is a fungal infection or bacterial spot, the visual representation highlights the most important parts of the leaf, guiding treatment decisions. In addition to disease detection, segmentation also aids in improving the efficiency of the system. By isolating the areas that matter most, it reduces the complexity of the image, speeding up the analysis and improving overall performance.
Implementation demo video drive link : https://drive.google.com/file/d/1fcnfVQbDTUwuCjn1L4zmfYvs5W1jOYhe/view?usp=sharing
